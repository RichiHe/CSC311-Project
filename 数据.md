## 核心：

1. **模型选择：** 多项式朴素贝叶斯 (MultinomialNB)。
2. **特征工程：**
   1. **文本：** 清洗 + TF-IDF (Sublinear) + 归一化。
   2. **评分：** One-Hot 编码（将 1-5 分拆解为 5 个独立状态）。
   3. **多选：** Multi-Hot 编码（拆解为 8 个独立选项）。
3. **特征选择：** 使用卡方检验 (SelectKBest) 剔除 25% 的噪音特征。
4. **数据清洗：** 正则表达式 + 停用词过滤 + 词干提取。



数据被拆分成三部分分别处理，最终在水平方向上合并。

- **部分 A: 文本特征 (X_text)**
  - **来源**: 单列文本 `In your own words...`。
  - **处理**:
    1. `clean_text_regex`: 转小写，去除非字母字符，去除停用词 (STOPWORDS)，简单的词干提取 (ing/ed/s)。
    2. `TfidfVectorizer`:
       - `ngram_range=(1, 1)`: 只看单词，不看词组。
       - `min_df=2`: **关键降噪**，只保留出现至少 2 次的词。
       - `sublinear_tf=True`: 使用 `1 + log(tf)` 平滑词频。
  - **维度**: **(825, V)**，其中 `V` 是最终词汇表的大小。根据您之前的日志，`V` 大约是 **745**。
- **部分 B: 评分特征 (X_rating)**
  - **来源**: 4 列评分问题 (`How likely...` 等)。
  - **处理**:
    1. `extract_rating`: 从字符串 `"5 - Very likely"` 中提取数字 `5`。
    2. `OneHotEncoder`: 将每个问题的评分 (1-5) 转换为 5 个独立的 0/1 特征。
  - **维度**: 4 个问题 $\times$ 5 个等级 = **(825, 20)**。
- **部分 C: 多选特征 (X_multi)**
  - **来源**: 2 列多选问题 (`Which types...` 等)。
  - **处理**:
    1. `process_multiselect`: 将逗号分隔的字符串解析为列表，并映射到 8 个规范选项。
    2. `MultiLabelBinarizer`: 对每个问题生成 8 个 0/1 特征。
  - **维度**: 2 个问题 $\times$ 8 个选项 = **(825, 16)**。
- **初步合并 (Merger)**:
  - `X_final = [X_text, X_rating, X_multi]`
  - **总维度**: $745 + 20 + 16 =$ **(825, 781)**。



#### **3. 特征筛选 (Feature Selection)**



- **输入**: (825, 781) 的矩阵。
- **处理**: `SelectKBest(chi2, k=420)`。
- **逻辑**: 计算每个特征与标签的卡方统计量，只保留得分最高的 420 个。
- **输出**: **(825, 420)**。这就是喂给模型训练的最终数据形态。



4. 